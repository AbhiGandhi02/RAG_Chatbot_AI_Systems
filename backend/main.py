"""
ClearPath RAG Chatbot — FastAPI Application

Main entry point. Serves the POST /query endpoint and the frontend chat UI.
Orchestrates: Router → Retriever → LLM → Evaluator → Response
"""

import logging
import json
import os
from contextlib import asynccontextmanager

from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, StreamingResponse
from sqlalchemy.ext.asyncio import AsyncSession

from backend.db.database import get_db, AsyncSessionLocal
from backend.db.models import User
from backend.db import crud
from backend.auth.dependencies import get_current_user

from backend.models.schemas import QueryRequest, QueryResponse, Metadata, Source, TokenUsage, ConversationUpdate
from backend.router.classifier import classify_query, create_routing_log
from backend.rag.retriever import Retriever
from backend.llm.groq_client import get_groq_client
from backend.evaluator.evaluator import evaluate_response, get_warning_message
from backend.config import PORT

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)
logger = logging.getLogger(__name__)

# Global instances (lazy initialized)
retriever = None
groq_client = None


@asynccontextmanager
async def lifespan(app):
    """Initialize retriever and LLM client on server startup."""
    global retriever, groq_client
    
    logger.info("Initializing ClearPath RAG Chatbot...")
    try:
        retriever = Retriever()
        logger.info("Retriever initialized successfully.")
    except Exception as e:
        logger.error(f"Failed to initialize retriever: {e}")
        logger.error("Run 'python -m backend.rag.embeddings' first to build the index.")
        raise
    
    try:
        groq_client = get_groq_client()
        logger.info("Groq client initialized successfully.")
    except Exception as e:
        logger.error(f"Failed to initialize Groq client: {e}")
        raise
    
    logger.info("ClearPath RAG Chatbot ready!")
    yield


app = FastAPI(
    title="ClearPath RAG Chatbot",
    description="Customer support chatbot for ClearPath project management tool",
    version="1.0.0",
    lifespan=lifespan
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# --- Conversation History Helpers ---

def generate_conversation_title(question: str) -> str:
    """Generate a short title based on the user's first question using Groq."""
    prompt = f"Write a short, concise 3 to 5 word title for a conversation that starts with this question:\n\n{question}\n\nDo not include quotes or extra text. Just the title."
    try:
        if groq_client:
            result = groq_client.generate(prompt, "", "llama-3.1-8b-instant")
            # Clear markdown bold asterisks and quotes
            return result["answer"].replace('*', '').strip(' "''')
    except Exception as e:
        logger.error(f"Title generation failed: {e}")
    return question[:30] + "..." if len(question) > 30 else question


async def get_or_create_conversation(db: AsyncSession, user: User, conversation_id: str = None, question: str = None):
    if conversation_id:
        conv = await crud.get_conversation(db, conversation_id, user.id)
        if not conv:
            raise HTTPException(status_code=403, detail="Conversation not found or access denied.")
        return conv
        
    title = generate_conversation_title(question) if question else "New Chat"
    return await crud.create_conversation(db, user.id, title=title)


async def get_formatted_history(db: AsyncSession, conversation_id: str, max_turns: int = 5):
    """Fetch history from DB and format for Groq LLM (list of dicts)."""
    messages = await crud.get_conversation_messages(db, conversation_id)
    # Get last N messages based on turns (each turn = 2 messages: user + assistant)
    recent_messages = messages[-(max_turns * 2):] if len(messages) > max_turns * 2 else messages
    
    history = []
    for msg in recent_messages:
        # We truncated assistant answers to 200 chars in memory before, do same here for context
        content = msg.content
        if msg.role == "assistant" and len(content) > 500:
            content = content[:500] + "..."
            
        history.append({
            "role": msg.role,
            "content": content
        })
    return history


# --- Main Endpoints ---

@app.post("/query", response_model=QueryResponse)
async def query(
    request: QueryRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """Main chatbot endpoint."""
    if not request.question or not request.question.strip():
        raise HTTPException(status_code=400, detail="Question cannot be empty")
    
    question = request.question.strip()
    
    # Get or create DB Conversation
    conv = await get_or_create_conversation(db, current_user, request.conversation_id, question=question)
    
    routing = classify_query(question)
    classification = routing["classification"]
    model_used = routing["model_used"]
    
    is_greeting = ("greeting_detected" in routing.get("signals", []) and len(question.split()) <= 5)
    
    history = await get_formatted_history(db, conv.id)
    
    if is_greeting:
        retrieved_chunks = []
        chunks_retrieved = 0
        context = "The user is greeting you. Respond warmly."
        llm_result = groq_client.generate(question, context, model_used, conversation_history=history)
        evaluator_flags = []
    else:
        retrieved_chunks = await retriever.retrieve_async(question)
        chunks_retrieved = len(retrieved_chunks)
        context = retriever.build_context(retrieved_chunks)
        llm_result = groq_client.generate(question, context, model_used, conversation_history=history)
        evaluator_flags = evaluate_response(llm_result["answer"], chunks_retrieved, retrieved_chunks)
    
    answer = llm_result["answer"]
    
    warning = get_warning_message(evaluator_flags)
    if warning:
        answer = f"{warning}\n\n{answer}"
    
    # Save the new turn to the DB
    await crud.add_message(db, conv.id, "user", question)
    await crud.add_message(db, conv.id, "assistant", answer)
    
    sources = [Source(document=c["document"], page=c["page"], relevance_score=c.get("relevance_score")) for c in retrieved_chunks]
    
    return QueryResponse(
        answer=answer,
        metadata=Metadata(
            model_used=model_used,
            classification=classification,
            tokens=TokenUsage(input=llm_result["tokens_input"], output=llm_result["tokens_output"]),
            latency_ms=llm_result["latency_ms"],
            chunks_retrieved=chunks_retrieved,
            evaluator_flags=evaluator_flags
        ),
        sources=sources,
        conversation_id=conv.id
    )


@app.post("/query/stream")
async def query_stream(
    request: QueryRequest,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """Streaming endpoint — returns tokens via Server-Sent Events (SSE)."""
    if not request.question or not request.question.strip():
        raise HTTPException(status_code=400, detail="Question cannot be empty")
    
    question = request.question.strip()
    
    conv = await get_or_create_conversation(db, current_user, request.conversation_id, question=question)
    
    routing = classify_query(question)
    classification = routing["classification"]
    model_used = routing["model_used"]
    
    is_greeting = ("greeting_detected" in routing.get("signals", []) and len(question.split()) <= 5)
    
    history = await get_formatted_history(db, conv.id)
    
    if is_greeting:
        retrieved_chunks = []
        context = "The user is greeting you. Respond warmly."
    else:
        retrieved_chunks = await retriever.retrieve_async(question)
        context = retriever.build_context(retrieved_chunks)
    
    sources = [{"document": c["document"], "page": c["page"], "relevance_score": c.get("relevance_score")} for c in retrieved_chunks]
    
    async def event_generator():
        full_answer = ""
        meta_event = {
            "type": "metadata",
            "classification": classification,
            "model_used": model_used,
            "chunks_retrieved": len(retrieved_chunks),
            "sources": sources,
            "conversation_id": conv.id
        }
        yield f"data: {json.dumps(meta_event)}\n\n"
        
        for chunk in groq_client.generate_stream(question, context, model_used, conversation_history=history):
            if chunk["type"] == "token":
                full_answer += chunk["content"]
                yield f"data: {json.dumps(chunk)}\n\n"
            elif chunk["type"] == "done":
                flags = [] if is_greeting else evaluate_response(full_answer, len(retrieved_chunks), retrieved_chunks)
                
                # Save to DB inside the generator using its own session context
                async with AsyncSessionLocal() as stream_db:
                    await crud.add_message(stream_db, conv.id, "user", question)
                    await crud.add_message(stream_db, conv.id, "assistant", full_answer)
                    await stream_db.commit()
                
                done_event = {
                    "type": "done",
                    "tokens_input": chunk["tokens_input"],
                    "tokens_output": chunk["tokens_output"],
                    "latency_ms": chunk["latency_ms"],
                    "evaluator_flags": flags
                }
                yield f"data: {json.dumps(done_event)}\n\n"
            elif chunk["type"] == "error":
                yield f"data: {json.dumps(chunk)}\n\n"
    
    return StreamingResponse(event_generator(), media_type="text/event-stream", headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"})


# --- Config Endpoint ---

@app.get("/api/firebase-config")
async def get_firebase_config():
    """Return public Firebase variables from the .env so they aren't hardcoded in JS."""
    return {
        "apiKey": os.getenv("FIREBASE_API_KEY"),
        "authDomain": os.getenv("FIREBASE_AUTH_DOMAIN"),
        "projectId": os.getenv("FIREBASE_PROJECT_ID"),
        "storageBucket": os.getenv("FIREBASE_STORAGE_BUCKET"),
        "messagingSenderId": os.getenv("FIREBASE_MESSAGING_SENDER_ID"),
        "appId": os.getenv("FIREBASE_APP_ID"),
        "measurementId": os.getenv("FIREBASE_MEASUREMENT_ID")
    }


# --- CRUD Endpoints for UI ---

@app.get("/conversations")
async def list_conversations(current_user: User = Depends(get_current_user), db: AsyncSession = Depends(get_db)):
    """List all conversations for the authenticated user."""
    convs = await crud.get_user_conversations(db, current_user.id)
    return [{"id": c.id, "title": c.title, "updated_at": c.updated_at} for c in convs]


@app.get("/conversations/{conversation_id}")
async def get_conversation_history_api(
    conversation_id: str, 
    current_user: User = Depends(get_current_user), 
    db: AsyncSession = Depends(get_db)
):
    """Get full message history for a specific conversation."""
    conv = await crud.get_conversation(db, conversation_id, current_user.id)
    if not conv:
        raise HTTPException(status_code=404, detail="Conversation not found")
        
    messages = await crud.get_conversation_messages(db, conversation_id)
    return [{"role": m.role, "content": m.content, "created_at": m.created_at} for m in messages]


@app.put("/conversations/{conversation_id}")
async def rename_conversation_api(
    conversation_id: str,
    update_data: ConversationUpdate,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """Rename a conversation."""
    if not update_data.title or not update_data.title.strip():
        raise HTTPException(status_code=400, detail="Title cannot be empty")
        
    conv = await crud.update_conversation(db, conversation_id, current_user.id, update_data.title.strip())
    if not conv:
        raise HTTPException(status_code=404, detail="Conversation not found")
    return {"status": "success", "title": conv.title}


@app.delete("/conversations/{conversation_id}")
async def delete_conversation_api(
    conversation_id: str, 
    current_user: User = Depends(get_current_user), 
    db: AsyncSession = Depends(get_db)
):
    """Delete a conversation."""
    success = await crud.delete_conversation(db, conversation_id, current_user.id)
    if not success:
        raise HTTPException(status_code=404, detail="Conversation not found")
    return {"status": "success"}


# --- Frontend & Health ---

frontend_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "frontend")
if os.path.exists(frontend_dir):
    app.mount("/static", StaticFiles(directory=frontend_dir), name="static")

@app.get("/")
async def serve_frontend():
    index_path = os.path.join(frontend_dir, "index.html")
    if os.path.exists(index_path):
        return FileResponse(index_path)
    return {"message": "ClearPath RAG API is running."}

@app.get("/health")
async def health():
    return {"status": "ok"}

if __name__ == "__main__":
    import uvicorn
    import os

    port = int(os.environ.get("PORT", 8000))
    uvicorn.run("backend.main:app", host="0.0.0.0", port=port)
